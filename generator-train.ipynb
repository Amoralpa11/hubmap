{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#  Image Segmentation","metadata":{}},{"cell_type":"markdown","source":"### Import modules","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\nfrom IPython.display import clear_output\nimport matplotlib.pyplot as plt\n\nimport time\n\nimport pandas as pd\n# General\nfrom glob import glob\nimport resource\nfrom tqdm.notebook import tqdm\n\n# Data Handling\nimport numpy as np\nimport pandas as pd\nimport json\n\n# Plotting\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n","metadata":{"ExecuteTime":{"end_time":"2021-02-27T13:06:31.905774Z","start_time":"2021-02-27T13:05:25.430194Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data loader ","metadata":{}},{"cell_type":"code","source":"info_df = pd.read_csv('hubmap-kidney-segmentation/HuBMAP-20-dataset_information.csv')","metadata":{"ExecuteTime":{"end_time":"2021-02-27T13:06:40.806429Z","start_time":"2021-02-27T13:06:40.724232Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('hubmap-kidney-segmentation/train.csv')\n\n# Unroll encoding column\ntemp_df = pd.DataFrame(columns=['id', 'start', 'run'])\nfor i, [image_id, encoding] in train_df.iterrows():\n    new_section = pd.DataFrame(columns=temp_df.columns)\n    encoding = encoding.split()\n    \n    start = encoding[::2]\n    run = encoding[1::2]\n    encoding = np.array(list(zip(start, run))).astype(int)\n    \n    new_section['start'] = encoding[:,0]\n    new_section['run'] = encoding[:,1]\n    new_section['id'] = image_id\n    \n    temp_df = temp_df.append(new_section)\ntrain_df = temp_df","metadata":{"ExecuteTime":{"end_time":"2021-02-27T13:06:46.779907Z","start_time":"2021-02-27T13:06:45.102936Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_data_json = {}\n\nfor i, row in info_df.iterrows():\n    image_file = row.image_file\n    image_id = image_file.split('.')[0]\n    \n    if image_id not in train_df.id.unique():\n        continue\n    \n    with open(f'hubmap-kidney-segmentation/train/{image_id}-anatomical-structure.json', 'r') as json_file:\n        anat_data = json.load(json_file)\n    with open(f'hubmap-kidney-segmentation/train/{image_id}.json', 'r') as json_file:\n        glom_data = json.load(json_file)\n        \n    image_data_json[image_id] = {'anat': anat_data, 'glom': glom_data}","metadata":{"ExecuteTime":{"end_time":"2021-02-27T13:06:55.536042Z","start_time":"2021-02-27T13:06:54.817854Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"glom_size_dict = {}\nfor image_id, data in image_data_json.items():\n    \n    glom_size_dict[image_id] = []\n    path = [p for p in glob('./*/*/*')if f'{image_id}.tiff' in p][0]\n\n\n    for glom in data['glom']:\n\n        polygon = np.array(glom['geometry']['coordinates']).reshape(-1, 2)\n        x = polygon[:, 0]\n        y = polygon[:, 1]\n\n        min_x = x.min()\n        max_x = x.max()\n        min_y = y.min()\n        max_y = y.max()\n\n        h = max_y-min_y\n        w = max_x-min_x\n        \n        \n        glom_size_dict[image_id].append(h*w)\n    \n    print(f'{image_id} glom size in squared pixels:{np.mean(glom_size_dict[image_id]):.3f}')","metadata":{"ExecuteTime":{"end_time":"2021-02-27T13:06:59.782876Z","start_time":"2021-02-27T13:06:59.651662Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_mask(image_id, window=None, out_shape=None):\n\n    w, h = info_df[info_df.image_file == image_id +\n                   '.tiff'][['width_pixels', 'height_pixels']].values.flatten()\n    \n    mask = np.zeros((w*h,), dtype=bool)\n\n    for i, row in train_df[train_df.id == image_id].iterrows():\n        start = row.start\n        mask[start] = 1\n\n        for j in range(row.run):\n            start += 1\n            mask[start] = 1\n\n    mask = mask.reshape(w, h).transpose()\n    \n    if window:\n        min_y, max_y, min_x, max_x = window\n        mask = mask[min_y:max_y, min_x:max_x]\n    \n    if out_shape:\n        mask = array_resize(mask, out_shape)\n    \n    return mask","metadata":{"ExecuteTime":{"end_time":"2021-02-27T13:07:02.890026Z","start_time":"2021-02-27T13:07:02.881718Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def array_resize(array, out_shape):\n    h, w = out_shape\n\n    row_idx = np.round(np.linspace(0, array.shape[0]-1, h)).astype(int)\n    col_idx = np.round(np.linspace(0, array.shape[1]-1, w)).astype(int)\n\n    array = array[row_idx][:,col_idx]\n    \n    return array","metadata":{"ExecuteTime":{"end_time":"2021-02-27T13:07:05.463888Z","start_time":"2021-02-27T13:07:05.45905Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_cortex_mask(image_id, sample, size=None, x_anchor=0, y_anchor=0):\n    anat_data = image_data_json[image_id]['anat']\n    \n    w, h = sample[['width_pixels', 'height_pixels' ]].values[0]\n    \n    if size:\n        w = h = size\n    \n    \n    # keep only the cortex information\n    cortex_data = [tissue for tissue in anat_data if tissue['properties']\n                   ['classification']['name'] == 'Cortex'][0]\n    # Extracting polygon vertex\n    polygon = np.array(cortex_data['geometry']['coordinates']).reshape(-1, 2)\n    if cortex_data['geometry']['type'] == 'Polygon':\n        polygon = np.array([polygon])\n    else:\n        polygon = np.array([polygon]).reshape(-1)\n        \n    cortex_mask_shape = (256,256)\n    \n    cortex_mask = np.zeros(cortex_mask_shape, dtype=bool)\n    \n    for subpolygon in polygon:\n        subpolygon = np.array(subpolygon)\n\n        subpolygon[:,0] -= x_anchor\n        subpolygon[:,1] -= y_anchor\n        \n        subpolygon[:,0] = subpolygon[:,0]/w*256\n        subpolygon[:,1] = subpolygon[:,1]/h*256        \n\n        cortex_mask = cortex_mask + polygon2mask(cortex_mask_shape, subpolygon[:,::-1])\n        \n    return cortex_mask","metadata":{"ExecuteTime":{"end_time":"2021-02-27T13:07:08.794264Z","start_time":"2021-02-27T13:07:08.786457Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_input_target():\n    # Pick a sample from the training dataset.\n    train_mask = info_df.image_file.isin(\n        [image+'.tiff' for image in train_df.id.unique()])\n    sample = info_df[train_mask].sample()\n\n    image_file, w, h = sample[['image_file',\n                               'width_pixels', 'height_pixels']].values[0]\n\n    image_id = image_file.split('.')[0]\n\n    # deciding area to cover\n    max_side = int(np.sqrt(np.array(glom_size_dict[image_id])).max())\n    size = np.random.randint(max_side, high=max_side*3)\n\n    # Deciding the localization of the image\n    x_anchor = np.random.randint(0, w-size)\n    y_anchor = np.random.randint(0, h-size)\n\n    # get image\n    path = [p for p in glob('./*/*/*')if f'{image_id}.tiff' in p][0]\n\n    with rasterio.open(path) as src:\n        sample_image = src.read(out_shape=(256, 256),\n                                window=Window.from_slices((y_anchor, y_anchor+size),\n                                                          (x_anchor, x_anchor+size)),\n                                resampling=rasterio.enums.Resampling.cubic)\n\n    sample_image = np.moveaxis(sample_image, 0, -1)\n\n    # Get corresponding mask\n    window = (y_anchor, y_anchor+size, x_anchor, x_anchor+size)\n    mask = get_mask(image_id, window, out_shape=(256, 256))\n\n    # Get the cortex mask\n    cortex_mask = get_cortex_mask(image_id, sample, size=size, x_anchor=x_anchor, y_anchor=y_anchor)\n\n    # Randomply flip the arrays along axis 1 and 2\n    flip_vertically = np.random.choice([-1, 1])\n    flip_horizontally = np.random.choice([-1, 1])\n    result = []\n    for channel in [sample_image, mask, cortex_mask]:\n        # apply transformatio\n        result.append(channel[::flip_vertically, ::flip_horizontally])\n    sample_image, mask, cortex_mask = result\n    \n    sample_image = sample_image/255\n    \n    input_image = np.concatenate([sample_image, cortex_mask[..., np.newaxis]], axis=-1)\n    \n    \n    # TODO include a parameter to generate n inputs and targets\n#     input_image = input_image[np.newaxis, ...].astype(np.float32)\n#     mask = mask[np.newaxis, ...].astype(np.float32)\n    \n    input_image = input_image.astype(np.float32)\n    mask = mask.astype(np.float32)\n    \n    return (input_image, mask)","metadata":{"ExecuteTime":{"end_time":"2021-02-27T13:07:15.748147Z","start_time":"2021-02-27T13:07:15.740319Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _bytes_feature(value):\n    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n    if isinstance(value, type(tf.constant(0))):\n        # BytesList won't unpack a string from an EagerTensor.\n        value = value.numpy()\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))","metadata":{"ExecuteTime":{"end_time":"2021-02-27T13:07:19.762549Z","start_time":"2021-02-27T13:07:19.755873Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def image_example():\n    \n    input_image, mask = get_input_target()\n\n    feature = {'image': _bytes_feature(input_image.tobytes()),\n                'target':_bytes_feature(mask.tobytes())}\n\n    return tf.train.Example(features=tf.train.Features(feature=feature))","metadata":{"ExecuteTime":{"end_time":"2021-02-27T13:07:20.273106Z","start_time":"2021-02-27T13:07:20.268697Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_num = 0\nfor file in glob('*.tfrecords'):\n    max_num = max(max_num, int(file.split('.')[0].split('_')[-1]))\nrecord_file = f\"image_{max_num+1}.tfrecords\"\n\nwith tf.io.TFRecordWriter(record_file) as writer:\n    for i in tqdm(range(2000)):\n        tf_example = image_example()\n        writer.write(tf_example.SerializeToString())","metadata":{"ExecuteTime":{"end_time":"2021-02-25T03:50:52.514124Z","start_time":"2021-02-24T22:43:53.788606Z"},"deletable":false,"editable":false,"run_control":{"frozen":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_image, mask = get_input_target()\n# Plot\nplt.figure(figsize=(15, 5))\nplt.subplot(1, 3, 1)\nplt.imshow(input_image[:,:,:3])\n\nplt.subplot(1, 3, 2)\nplt.imshow(mask)\n\nplt.subplot(1, 3, 3)\nplt.imshow(input_image[:,:,3])\n\nplt.show()","metadata":{"ExecuteTime":{"end_time":"2021-02-27T13:08:11.763945Z","start_time":"2021-02-27T13:07:27.324855Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Input pipeline","metadata":{}},{"cell_type":"code","source":"dataset = tf.data.TFRecordDataset(filenames = glob(\"*tfrecord*\"))","metadata":{"ExecuteTime":{"end_time":"2021-02-27T13:10:12.126157Z","start_time":"2021-02-27T13:10:11.331736Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_image_from_example(raw_example):\n    parsed = tf.train.Example.FromString(raw_example.numpy())\n    \n    target_bytes_string = parsed.features.feature['target'].bytes_list.value[0]\n    image_bytes_string = parsed.features.feature['image'].bytes_list.value[0]\n    \n    mask = np.frombuffer(image_bytes_string, dtype='<f4').reshape(256,256, 1)\n    input_image = np.frombuffer(target_bytes_string, dtype='<f4').reshape(256,256,4)\n    \n    return mask, input_image","metadata":{"ExecuteTime":{"end_time":"2021-02-27T13:10:13.305146Z","start_time":"2021-02-27T13:10:13.301344Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def batch_generator(epochs, batch_size):\n    batched_dataset = dataset.batch(batch_size)\n    for epoch in range(epochs):\n        for batch in batched_dataset:\n            image_list = []\n            target_list = []\n\n            for example in batch:\n                target, input_image = get_image_from_example(example)\n\n                image_list.append(input_image)\n                target_list.append(target)\n            image_list = np.stack(image_list)\n            target_list = np.stack(target_list)\n\n            yield (image_list, target_list)","metadata":{"ExecuteTime":{"end_time":"2021-02-27T13:10:14.24777Z","start_time":"2021-02-27T13:10:14.244053Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define the model","metadata":{}},{"cell_type":"code","source":"OUTPUT_CHANNELS = 0","metadata":{"ExecuteTime":{"end_time":"2021-02-27T13:10:21.236467Z","start_time":"2021-02-27T13:10:21.223996Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def downsample(filters, size, apply_batchnorm=True):\n    initializer = tf.random_normal_initializer(0., 0.02)\n\n    result = tf.keras.Sequential()\n    result.add(\n        tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n                               kernel_initializer=initializer, use_bias=False))\n\n    if apply_batchnorm:\n        result.add(tf.keras.layers.BatchNormalization())\n\n    result.add(tf.keras.layers.LeakyReLU())\n\n    return result","metadata":{"ExecuteTime":{"end_time":"2021-02-27T13:10:21.646689Z","start_time":"2021-02-27T13:10:21.640643Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def upsample(filters, size, apply_dropout=False):\n    initializer = tf.random_normal_initializer(0., 0.02)\n\n    result = tf.keras.Sequential()\n    result.add(\n        tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n                                        padding='same',\n                                        kernel_initializer=initializer,\n                                        use_bias=False))\n\n    result.add(tf.keras.layers.BatchNormalization())\n\n    if apply_dropout:\n        result.add(tf.keras.layers.Dropout(0.5))\n\n    result.add(tf.keras.layers.ReLU())\n\n    return result","metadata":{"ExecuteTime":{"end_time":"2021-02-27T13:10:22.028764Z","start_time":"2021-02-27T13:10:22.009892Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Generator():\n    \n    inputs = tf.keras.layers.Input(shape=[256, 256, 4])\n\n    down_stack = [\n        downsample(64, 4, apply_batchnorm=False),  # (bs, 128, 128, 64)\n        downsample(128, 4),  # (bs, 64, 64, 128)\n        downsample(256, 4),  # (bs, 32, 32, 256)\n        downsample(512, 4),  # (bs, 16, 16, 512)\n        downsample(512, 4),  # (bs, 8, 8, 512)\n        downsample(512, 4),  # (bs, 4, 4, 512)\n        downsample(512, 4),  # (bs, 2, 2, 512)\n        downsample(512, 4),  # (bs, 1, 1, 512)\n    ]\n\n    up_stack = [\n        upsample(512, 4, apply_dropout=True),  # (bs, 2, 2, 1024)\n        upsample(512, 4, apply_dropout=True),  # (bs, 4, 4, 1024)\n        upsample(512, 4, apply_dropout=True),  # (bs, 8, 8, 1024)\n        upsample(512, 4),  # (bs, 16, 16, 1024)\n        upsample(256, 4),  # (bs, 32, 32, 512)\n        upsample(128, 4),  # (bs, 64, 64, 256)\n        upsample(64, 4),  # (bs, 128, 128, 128)\n    ]\n\n    initializer = tf.random_normal_initializer(0., 0.02)\n    last = tf.keras.layers.Conv2DTranspose(1, 4,\n                                           strides=2,\n                                           padding='same',\n                                           kernel_initializer=initializer,\n                                           activation='sigmoid')  # (bs, 256, 256, 3)\n\n    x = inputs\n\n    # Downsampling through the model\n    skips = []\n    for down in down_stack:\n        x = down(x)\n        skips.append(x)\n\n    skips = reversed(skips[:-1])\n\n    # Upsampling and establishing the skip connections\n    for up, skip in zip(up_stack, skips):\n        x = up(x)\n        x = tf.keras.layers.Concatenate()([x, skip])\n\n    x = last(x)\n\n    return tf.keras.Model(inputs=inputs, outputs=x)","metadata":{"ExecuteTime":{"end_time":"2021-02-27T13:10:22.493051Z","start_time":"2021-02-27T13:10:22.484773Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator = Generator()\ntf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)","metadata":{"ExecuteTime":{"end_time":"2021-02-27T13:10:26.119581Z","start_time":"2021-02-27T13:10:24.349707Z"},"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train the model","metadata":{}},{"cell_type":"code","source":"def generate_images(input_image, mask):    \n\n    pred = generator.predict(input_image.copy()[np.newaxis, ...]).reshape(256,256, 1)\n    \n    print(dice_coef(pred, mask))\n\n    # Plot\n    plt.figure(figsize=(15, 15))\n    plt.subplot(2, 2, 1)\n    plt.imshow(input_image[:,:,:3])\n\n    plt.subplot(2, 2, 2)\n    plt.imshow(mask)\n\n    plt.subplot(2, 2, 3)\n    plt.imshow(input_image[:,:,3])\n\n    plt.subplot(2, 2, 4)\n    plt.imshow(pred)\n\n    plt.show()\n    \n    return input_image, mask","metadata":{"ExecuteTime":{"end_time":"2021-02-27T13:22:24.941379Z","start_time":"2021-02-27T13:22:24.936839Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dice_coef(a, b, smooth=1e-5):\n    \n    sum_a = tf.reduce_sum(a)\n    sum_b = tf.reduce_sum(b)\n    \n    join_sum = tf.reduce_sum(tf.multiply(a, b))\n\n    dice = -(join_sum*2+smooth)/(sum_a+sum_b+smooth)+1\n    \n    return dice","metadata":{"ExecuteTime":{"end_time":"2021-02-27T13:11:13.319277Z","start_time":"2021-02-27T13:11:13.315939Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator_optimizer = tf.keras.optimizers.Adam(2e-3, beta_1=0.5)","metadata":{"ExecuteTime":{"end_time":"2021-02-27T13:11:12.585756Z","start_time":"2021-02-27T13:11:12.581989Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator.compile(generator_optimizer,dice_coef)","metadata":{"ExecuteTime":{"end_time":"2021-02-27T13:11:14.41912Z","start_time":"2021-02-27T13:11:14.395547Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 16\nepochs = 10\nsteps_per_epoch = int(2000/batch_size)","metadata":{"ExecuteTime":{"end_time":"2021-02-27T13:22:45.185872Z","start_time":"2021-02-27T13:22:45.183289Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator.fit(batch_generator(epochs, batch_size),\n              steps_per_epoch=steps_per_epoch, epochs=epochs)","metadata":{"ExecuteTime":{"start_time":"2021-02-27T16:35:01.357Z"},"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checkpoint_dir = './training_checkpoints'\n# checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n# checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n#                                  generator=generator)","metadata":{"ExecuteTime":{"end_time":"2021-02-26T23:05:39.03361Z","start_time":"2021-02-26T23:05:39.031054Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# @tf.function\ndef train_step(input_image, target, step):\n    with tf.GradientTape() as gen_tape:\n        \n        gen_output = generator(input_image, training=True)\n\n#         gen_total_loss = generator_loss(gen_output, target)\n\n        gen_output = tf.reshape(gen_output, (256,256))\n        gen_total_loss = dice_coef(gen_output, target)\n        \n\n#     generate_images(input_image, target, gen_output)\n\n#     tf.print(gen_total_loss)\n\n\n    generator_gradients = gen_tape.gradient(gen_total_loss,\n                                            generator.trainable_variables)\n\n\n    generator_optimizer.apply_gradients(zip(generator_gradients,\n                                            generator.trainable_variables))\n\n#     with summary_writer.as_default():\n#         tf.summary.scalar('gen_total_loss', gen_total_loss, step=step)","metadata":{"ExecuteTime":{"end_time":"2021-02-26T23:09:11.965282Z","start_time":"2021-02-26T23:09:11.951952Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.newaxis","metadata":{"ExecuteTime":{"end_time":"2021-02-27T00:42:13.03712Z","start_time":"2021-02-27T00:42:13.03422Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_image.shape","metadata":{"ExecuteTime":{"end_time":"2021-02-27T00:42:55.074613Z","start_time":"2021-02-27T00:42:55.06188Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit(epochs):\n\n    for epoch in range(epochs):\n        start = time.time()\n\n        clear_output(wait=True)\n\n#         clear_output(wait=True)\n\n#         if (step + 1) % 5 == 0:\n#             generate_images()\n\n        print(\"Epoch: \", epoch)\n\n        # Train\n#         input_image, target = get_input_target()\n\n        for n, raw_example in dataset.enumerate():\n            print('.', end='')\n            if (n+1) % 100 == 0:\n                print()\n            target, input_image = get_image_from_example(raw_example)\n\n            train_step(input_image, target, epoch)\n\n        print()\n\n#         # saving (checkpoint) the model every 20 epochs\n#         if (epoch + 1) % 20 == 0:\n#             checkpoint.save(file_prefix=checkpoint_prefix)\n\n        print('Time taken for step {} is {} sec\\n'.format(\n            step + 1, time.time()-start))\n#     checkpoint.save(file_prefix=checkpoint_prefix)","metadata":{"ExecuteTime":{"end_time":"2021-02-26T23:07:16.367044Z","start_time":"2021-02-26T23:07:16.348469Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 100\n\nfit(EPOCHS)","metadata":{"ExecuteTime":{"end_time":"2021-02-26T23:22:49.79097Z","start_time":"2021-02-26T23:09:15.298637Z"},"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for n, raw_example in dataset.enumerate():\n    target, input_image = get_image_from_example(raw_example)\n    \n    generate_images(input_image, target)\n    \n    input()\n    clear_output(wait=False)","metadata":{"ExecuteTime":{"end_time":"2021-02-27T16:34:59.057044Z","start_time":"2021-02-27T16:33:16.335329Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator.fit()","metadata":{},"execution_count":null,"outputs":[]}]}